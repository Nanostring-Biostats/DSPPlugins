# SpatialDecon: mixed cell deconvolution for spatial and/or bulk gene expression data
# Copyright (C) 2020, NanoString Technologies, Inc.
#    This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.
#    This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.
#    You should have received a copy of the GNU General Public License along with this program.  If not, see https://www.gnu.org/licenses/.
# Contact us:
# NanoString Technologies, Inc.
# 530 Fairview Avenue N
# Seattle, WA 98109
# Tel: (888) 358-6266
# pdanaher@nanostring.com


##########################################################
####      Arguments to be modified by user            #### 
##########################################################


# Specify the filename of the cell profile matrix:
# Instructions: specifying a new cell profile matrix: 
#   Use a .csv file with cell-type-specific expression profiles, with genes in 
#   rows and cell types in columns. Row names should be in HUGO gene names.
# Instructions: downloading a pre-specified cell profile matrix:
#   You can supply your own cell profile matrix, or you can download a pre-specified one from
#   https://github.com/Nanostring-Biostats/Extensions/cell-profile-library
# Instructions: uploading to DSPDA:
# ______________
cell_profile_filename = "safeTME-for-tumor-immune.csv"

# if you have segments selected to be pure tumor, free of immune and stroma, 
# then specify a column name giving the identities of those segments. The 
# code expects this column to have"tumor" entered for those segments, and other
# values elsewhere. 
pure_tumor_column_name = "none"

# enter the name of the column giving nuclei counts
nuclei_count_column_name = "AOINucleiCount"

# define cell types to be added together in the final result:
# example syntax:
# merges = list()
# merges[["T"]] = c("CD8.T", "CD4.T")
# merges[["myeloid"]] = c("macrophage", "monocyte", "DC")
merges = list()


##########################################################
#### end of arguments. DO NOT CHANGE CODE BELOW HERE  ####
##########################################################

library(logNormReg)
library(pheatmap)
library(viridis)

main <- function(dataset, segmentAnnotations, targetAnnotations, outputFolder) {
  
  #### preliminaries ----------------------
  dataset = as.matrix(dataset)
  
  # access cell profile matrix file:
  X = as.matrix(read.csv(cell_profile_filename, header = T, row.names = 1))
  
  # parse merges:
  merges.full = NULL
  if (length(merges) > 0) {
    # initialize with 1:1 mapping:
    merges.full = list()
    for (name in colnames(X)) {
      merges.full[[name]] = name
    }
    # add merges:
    for (name in names(merges0)) {
      # remove entries for cells specified by user and replace with their entries:
      merges.full[merges[[name]]] = NULL
      merges.full[[name]] = merges[[name]]
    }
  }
  
  # parse nuclei column
  cell_counts = NULL
  if (is.element(nuclei_count_column_name, colnames(targetAnnotations))) {
    cell_counts = as.numeric(targetAnnotations[, nuclei_count_column_name])
  }
  if (!is.element(nuclei_count_column_name, colnames(targetAnnotations))) {
    warning("The value entered for nuclei_count_column_name was not a column header in the target annotations. 
            Results will not be output on the scale of cell counts; just in abundance scores and proportions.")
  }
    
  # parse pure tumor column
  is_pure_tumor = NULL
  if (is.element(pure_tumor_column_name, colnames(targetAnnotations))) {
    is_pure_tumor = targetAnnotations[, pure_tumor_column_name] == "tumor"
    is_pure_tumor = replace(is_pure_tumor, is.na(is_pure_tumor), FALSE)
  }
  if (!is.element(pure_tumor_column_name, colnames(targetAnnotations)) & (pure_tumor_column_name != "none")) {
    warning("The value entered for pure_tumor_column_name was not a column header in the target annotations.")
  }
  
  # format data for spatialdecon:
  norm = dataset[targetAnnotations$TargetGUID, segmentAnnotations$segmentID]
  rownames(norm) = targetAnnotations$TargetName
  colnames(norm) = segmentAnnotations$segmentDisplayName

  # calculate background:
  bg = derive_GeoMx_background(norm = norm,
                               probepool = targetAnnotations$ProbePool,
                               negnames = targetAnnotations$TargetName[targetAnnotations$CodeClass == "Negative"])
  
  
  
  #### run decon: ----------------------------------------
  # decon:
  res = spatialdecon(norm = norm,
                     bg = bg, 
                     X = X, 
                     is_pure_tumor = is_pure_tumor, 
                     cell_counts = cell_counts, 
                     cellmerges = merges.full)
  
  # reverse decon:
  rdecon = reverseDecon(norm = norm, 
                        beta = res$beta, 
                        epsilon = NULL)
  
  
  #### write results files: ---------------------------------------------
  write.csv(res$beta, file = file.path(outputFolder, "cell_abundance_scores.csv", fsep = .Platform$file.sep))
  write.csv(res$p, file = file.path(outputFolder, "cell_pvalues.csv", fsep = .Platform$file.sep))
  if (is.element("cell.counts", names(res))) {
    write.csv(res$cell.counts, file = file.path(outputFolder, "cell_count_estimates.csv", fsep = .Platform$file.sep))
  }  
  if (is.element("beta.granular", names(res))) {
    write.csv(res$beta.granular, file = file.path(outputFolder, "cell_abundance_scores_granular.csv", fsep = .Platform$file.sep))
  }
  if (is.element("cell.counts.granular", names(res))) {
    write.csv(res$cell.counts.granular, file = file.path(outputFolder, "cell_count_estimates_granular.csv", fsep = .Platform$file.sep))
  }   
  
  # reverse decon resids
  write.csv(rdecon$resids, file = file.path(outputFolder, "reverse_decon_residuals.csv", fsep = .Platform$file.sep))

  # reverse decon summary stats of gene dependency on cell mixing:
  sumstats = cbind(rdecon$cors, rdecon$resid.sd)
  colnames(sumstats) = c("cor w cell mixing", "residual SD from cell mixing")
  write.csv(sumstats, file = file.path(outputFolder, "reverse_decon_residuals.csv", fsep = .Platform$file.sep))
  
  #### results figures: ---------------------------------------------
  
  # show just the original cells, not tumor abundance estimates derived from the is.pure.tumor argument:
  cells.to.plot = intersect(rownames(res$beta), union(colnames(X), names(merges.full)))
  
  # heatmap
  pdf(file = file.path(outputFolder, "cell_abundance_heatmap.pdf", fsep = .Platform$file.sep), width = 12)
  pheatmap(res$beta[cells.to.plot, ],
           col = viridis_pal(option = "B")(100),
           fontsize_col = 4)
  dev.off()
 
  # barplot
  pdf(file = file.path(outputFolder, "cell_abundance_barplot.pdf", fsep = .Platform$file.sep), width = 12)
  par(mar = c(15,5,2,1))
  TIL_barplot(mat = res$beta[cells.to.plot, ],
              draw_legend = TRUE)
  dev.off()
  
}



#### below here: all the functions of the SpatialDecon package ####





#' SpatialDecon mixed cell deconvolution algorithm
#'
#' Runs the generic SpatialDecon decon workflow, including:
#' \enumerate{
#' \item run deconvolution once
#' \item remove poorly-fit genes from first round of decon
#' \item re-run decon with cleaned-up gene set
#' \item compute p-values
#' }
#'
#' @param Y p-length expression vector or p * N expression matrix - the actual (linear-scale) data
#' @param X p * K Training matrix.
#' @param bg Expected background counts. Provide a scalar to apply to all data points, or
#'  else a matrix/vector aligning with Y to provide more nuanced expected background.
#' @param weights The same as the weights argument used by lm
#' @param resid_thresh A scalar, sets a threshold on how extreme individual data points' values
#'  can be (in log2 units) before getting flagged as outliers and set to NA.
#' @param lower_thresh A scalar. Before log2-scale residuals are calculated, both observed and fitted
#'  values get thresholded up to this value. Prevents log2-scale residuals from becoming extreme in
#'  points near zero.
#' @param align_genes Logical. If TRUE, then Y, X, bg, and wts are row-aligned by shared genes.
#' @param maxit Maximum number of iterations. Default 1000.
#' @return a list:
#' \itemize{
#' \item beta: matrix of cell abundance estimates, cells in rows and observations in columns
#' \item sigmas: covariance matrices of each observation's beta estimates
#' \item p: matrix of p-values for H0: beta == 0
#' \item t: matrix of t-statistics for H0: beta == 0
#' \item se: matrix of standard errors of beta values
#' \item resids: a matrix of residuals from the model fit. (log2(pmax(y, lower_thresh)) - log2(pmax(xb, lower_thresh))).
#' }
#' @export
algorithm2 <- function(Y, X, bg = 0, weights = NULL,
                       resid_thresh = 3, lower_thresh = 0.5,
                       align_genes = TRUE, maxit = 1000) {

  # align genes:
  if (align_genes) {
    sharedgenes <- intersect(rownames(X), rownames(Y))
    Y <- Y[sharedgenes, ]
    X <- X[sharedgenes, ]
    if (is.matrix(bg)) {
      bg <- bg[sharedgenes, ]
    }
    if (is.matrix(weights)) {
      weights <- weights[sharedgenes, ]
    }
  }

  # format the data nicely:
  tidied <- tidy_X_and_Y(X, Y)
  X <- tidied$X
  Y <- tidied$Y
  if ((length(bg) > 0) & (is.vector(bg))) {
    bg <- matrix(bg, nrow = length(bg))
  }

  # select an epsilon (lowest non-zero value to use)
  epsilon <- min(Y[(Y > 0) & !is.na(Y)])


  # initial run to look for outliers:
  out0 <- deconLNR(Y = Y, X = X, bg = bg, weights = weights, epsilon = epsilon, maxit = maxit)
  # also get yhat and resids:
  out0$yhat <- X %*% out0$beta + bg
  out0$resids <- log2(pmax(Y, lower_thresh)) - log2(pmax(out0$yhat, lower_thresh))

  # ID bad genes:
  outliers <- flagOutliers(
    Y = Y,
    yhat = out0$yhat,
    wts = weights,
    resids = out0$resids,
    resid_thresh = resid_thresh
  )

  # remove outlier data points:
  Y.nooutliers <- replace(Y, outliers, NA)

  # re-run decon without outliers:
  out <- deconLNR(Y = Y.nooutliers, X = X, bg = bg, weights = weights, epsilon = epsilon)
  out$yhat <- X %*% out$beta + bg
  out$resids <- log2(pmax(Y.nooutliers, 0.5)) - log2(pmax(out$yhat, 0.5))

  # compute p-values
  tempbeta <- out$beta
  tempse <- tempp <- tempt <- tempbeta * NA
  for (i in seq_len(ncol(tempse))) {
    tempse[, i] <- suppressWarnings(sqrt(diag(out$sigmas[, , i])))
  }
  tempt <- (tempbeta / tempse)
  tempp <- 2 * (1 - stats::pt(tempt, df = nrow(X) - ncol(X) - 1))
  out$p <- tempp
  out$t <- tempt
  out$se <- tempse

  # structure of output: beta, hessians, yhat, resids
  return(out)
}



#' Function to format Y, X inputs for decon
#'
#' Takes user-supplied X and Y, checks for accuracy, aligns by dimnames, adds dimnames if missing
#'
#' @param X X matrix
#' @param Y Data matrix
#' @return X and Y, both formatted as matrices, with full dimnames and aligned to each other by dimname
tidy_X_and_Y <- function(X, Y) {

  # format as matrices:
  Ynew <- Y
  if (is.vector(Y)) {
    Ynew <- matrix(Y, nrow = length(Y), dimnames = list(names(Y), "y"))
  }
  Xnew <- X

  # check alignment:
  if (!identical(rownames(Y), rownames(X))) {
    warning("Rows (genes) of X and Y are mis-aligned.")
  }
  out <- list(X = Xnew, Y = Ynew)
}




#' Collapse related cell types within a deconvolution result
#'
#' Given the input of an SpatialDecon result output and a list of which cell types to combine,
#'  returns a reshaped deconvolution result object with the specified cell types merged.
#' @param fit The object (a list) returned by the SpatialDecon algorithm
#' @param matching A list object holding the mapping from beta's cell names to official cell names.
#'  See str(safeTME.matches) for an example.
#' @return A reshaped deconvolution result object
#' @examples
#' data(mini_geomx_dataset)
#' # estimate background:
#' mini_geomx_dataset$bg <- derive_GeoMx_background(
#'   norm = mini_geomx_dataset$normalized,
#'   probepool = rep(1, nrow(mini_geomx_dataset$normalized)),
#'   negnames = "NegProbe"
#' )
#' # run basic decon:
#' res0 <- spatialdecon(
#'   norm = mini_geomx_dataset$normalized,
#'   bg = mini_geomx_dataset$bg,
#'   X = safeTME
#' )
#' res1 <- collapseCellTypes(fit = res0, matching = SpatialDecon::safeTME.matches)
#' @export
collapseCellTypes <- function(fit, matching) {

  # results object to hold the collapsed results:
  out <- fit

  # format matching list as a matrix to take a linear combination of beta:
  startingcellnames <- unlist(matching)
  A <- matrix(0, length(matching), nrow(fit$beta), dimnames = list(names(matching), rownames(fit$beta)))
  for (name in names(matching)) {
    cellnames <- matching[[name]]
    A[name, cellnames] <- 1
  }

  # apply A transformation to beta:
  for (name in c("beta", "prop_of_all", "prop_of_nontumor")) {
    if (is.element(name, names(fit))) {
      out[[name]] <- A[, startingcellnames] %*% fit[[name]][startingcellnames, ]
    }
  }

  # if Sigma provided, get vcov of beta2:
  if (is.element("sigmas", names(out))) {
    sigma <- fit$sigmas
    if (length(dim(sigma)) == 2) {
      out$sigmas <- A[, startingcellnames] %*% sigma[startingcellnames, startingcellnames, ] %*% t(A[, startingcellnames])
    }
    if (length(dim(sigma)) == 3) {
      out$sigmas <- array(NA,
        dim = c(nrow(A), nrow(A), dim(sigma)[3]),
        dimnames = list(rownames(A), rownames(A), dimnames(sigma)[[3]])
      )
      for (i in seq_len(dim(sigma)[3])) {
        out$sigmas[, , i] <- A %*% sigma[, , i] %*% t(A)
      }
    }
  }

  # re-calculate p, se, t:
  if (is.element("beta", names(out)) & is.element("sigmas", names(out))) {
    # compute p-values
    tempbeta <- out$beta
    tempse <- tempp <- tempt <- tempbeta * NA
    for (i in seq_len(ncol(tempse))) {
      tempse[, i] <- suppressWarnings(sqrt(diag(out$sigmas[, , i])))
    }
    out$se <- tempse
    out$t <- (tempbeta / tempse)
    if (is.element("X", names(out))) {
      out$p <- 2 * (1 - stats::pt(out$t, df = nrow(fit$X) - ncol(fit$X) - 1))
    }
  }

  return(out)
}




#' Convert abundance measurements to cell counts
#'
#' Converts cell abundance scores to cell counts, under the assumption that the observation with
#'  the greatest sum of cell abundance scores is 100% modelled cells.
#' @param beta Matrix of cell abundance scores, with cells in rows and observations in columns. The
#'  assumption is that this matrix is from well-normalized data.
#' @param nuclei.counts Optional. A vector of total nuclei counts. If provided, the function will
#'  output not only cells.per.100 but also total cells.
#' @param omit.tumor Logical. If FALSE, any rows of beta with "tumor" in their name will be omitted.
#' @return A list with two elements, each a rescaled version of beta. cells.per.100 gives estimated
#'  percents of total, and cell.counts is cells.per.100 * nuclei.counts.
convertCellScoresToCounts <- function(beta, nuclei.counts = NULL, omit.tumor = FALSE) {
  # strip tumor rows if called for:
  if (omit.tumor) {
    beta <- beta[!grepl("tumor", rownames(beta)), , drop = FALSE]
  }

  # calc max abundance scores:
  max.total.abundance <- max(colSums(beta))

  # calculate rescaled scores:
  out <- list()
  out$cells.per.100 <- beta / max.total.abundance * 100
  if (length(nuclei.counts) == ncol(beta)) {
    out$cell.counts <- sweep(out$cells.per.100, 2, nuclei.counts, "*") / 100
  }
  return(out)
}





#' Convert results from an arbitrary training matrix to our standardized cell types.
#'
#' Takes betas from a decon run, using any cell type names whatsoever, and maps them back to the
#' "official" cell types we use. Allows for multiple rows of beta to map to the same official cell type,
#' in which case those rows will be added up.
#'
#' @param beta K * n matrix of estimated beta values (cell type abundances)
#' @param matching A list object holding the mapping from beta's cell names to official cell names.
#'  See str(safeTME.matches) for an example.
#' @param stat The function used to combine related cell types. Defaults to sum.
#' @param na.rm Whether to ignore NAs while computing stat
#' @param sigma A list of covariance matrices of beta estimates, in the format output by spatialdecon.
#' @return A list with two elements:
#' \itemize{
#' \item beta: a matrix of cell abundances, with specified cell types added together
#' \item sigma: an array of covariance matrices for each observation's beta vector
#' }
convertCellTypes <- function(beta, matching, stat = sum, na.rm = FALSE, sigma = NULL) {
  # format matching list as a matrix to take a linear combination of beta:
  A <- matrix(0, length(matching), nrow(beta), dimnames = list(names(matching), rownames(beta)))
  for (name in names(matching)) {
    cellnames <- matching[[name]]
    A[name, cellnames] <- 1
  }

  # apply A transformation to beta:
  beta2 <- A %*% beta

  # if Sigma provided, get vcov of beta2:
  if (length(sigma) > 0) {
    if (length(dim(sigma)) == 2) {
      sigma2 <- A %*% sigma %*% t(A)
    }
    if (length(dim(sigma)) == 3) {
      sigma2 <- array(NA,
        dim = c(nrow(A), nrow(A), dim(sigma)[3]),
        dimnames = list(rownames(A), rownames(A), dimnames(sigma)[[3]])
      )
      for (i in seq_len(dim(sigma)[3])) {
        sigma2[, , i] <- A %*% sigma[, , i] %*% t(A)
      }
    }
  }

  # if no Sigma, just return transformed beta:
  if (length(sigma) == 0) {
    return(beta2)
  }
  # if there is a sigma, return beta and the sigma:
  if (length(sigma) > 0) {
    out <- list(beta = beta2, sigma = sigma2)
    return(out)
  }
}

#' Default colors for the cell types in the safeTME matrix
#'
#' A named vector of colors, giving colors for the cell types of the safeTME matrix.
#'
#' @format A named vector
"cellcols"


#' Default colors for the cell types in the safeTME matrix
#'
#' A named vector of colors, giving colors for the cell types of the safeTME matrix.
#'
#' @format A named vector
"mini_geomx_dataset"


#' Mapping from granularly-defined cell populations to broaded cell populations
#'
#' Mapping from granularly-defined cell populations to broaded cell populations,
#'  for use by the convertCellTypes function.
#'
#' @format A list. Each element of the list contains the granular cell types that roll up
#'  to a single coarse cell type.
"safeTME.matches"


#' SafeTME matrix
#'
#' A matrix of expression profiles of 906 genes over 18 cell types.
#'
#' @format A matrix with 906 genes (rows) and 18 cell types (columns)
"safeTME"


#' Genes' biological variability in immune deconvolution from TCGA.
#'
#' Genes' biological SDs, as estimated from immune deconvolution from TCGA. Used to weight
#'  genes in spatialdecon.
#'
#' @format A named vector giving SDs of 1179 genes.
"mean.resid.sd"





#' Deconvolution using logNormReg package to run linear mean model and log error model
#'
#' Calls lognlm() to optimize the model.
#'
#' @param Y p-length expression vector or p * N expression matrix - the actual (linear-scale) data
#' @param X p * K Training matrix
#' @param bg scalar or matrix of expected background counts per data point.
#' @param weights The same as the weights argument used by lm
#' @param epsilon optional,  a very small non-zero number to use as a lower threshold to make fits well-behaved
#' @param maxit Maximum number of iterations. Default 1000.
#' @return a list: beta (estimate), sigmas (covariance matrix of estimate, derived by inverting the hessian from lognlm)
#' @import logNormReg
deconLNR <- function(Y, X, bg = 0, weights = NULL, epsilon = NULL, maxit = 1000) {
  if (length(weights) == 0) {
    weights <- replace(Y, TRUE, 1)
  }
  if (is.vector(Y)) {
    Y <- matrix(Y, nrow = length(Y))
  }
  if (length(bg) == 1) {
    bg <- matrix(bg, nrow(Y), ncol(Y))
  }
  # choose "epsilon": a very small non-zero number to make fits well-behaved
  if (length(epsilon) == 0) {
    epsilon <- min(replace(Y, (Y == 0) & !is.na(Y), NA), na.rm = TRUE)
  }

  # matrix-like data for apply:
  mat <- rbind(Y, bg, weights)
  # fn to apply:
  fn <- function(zz) {
    # break into y, b, w:
    y <- zz[seq_len((length(zz)) / 3)]
    b <- zz[seq_len((length(zz)) / 3) + (length(zz) / 3)]
    wts <- zz[seq_len((length(zz)) / 3) + (length(zz) / 3) * 2]

    # remove NA data:
    use <- !is.na(y)
    y <- y[use]
    b <- b[use]
    Xtemp <- X[use, , drop = FALSE]
    wts <- wts[use]

    init <- rep(mean(y) / (mean(X) * ncol(X)), ncol(X))
    names(init) <- colnames(X)

    # run lognlm:
    fit <- lognlm(pmax(y, epsilon) ~ b + Xtemp - 1,
      lik = FALSE,
      weights = wts,
      start = c(1, init),
      method = "L-BFGS-B",
      lower = c(1, rep(0, ncol(Xtemp))),
      upper = c(1, rep(Inf, ncol(Xtemp))),
      opt = "optim",
      control = list(maxit = maxit)
    )
    fnout <- list(
      beta = fit$coefficients[-1],
      sigma = solve(fit$hessian)[-1, -1]
    )
    return(fnout)
  }
  # apply across all observations:
  fnlist <- apply(mat, 2, fn)
  # extract beta and sigmas:
  getbeta <- function(zz) {
    return(zz$beta)
  }
  getsigma <- function(zz) {
    return(zz$sigma)
  }

  beta <- sapply(fnlist, getbeta)
  rownames(beta) <- colnames(X)
  sigmas <- array(sapply(fnlist, getsigma),
    dim = c(ncol(X), ncol(X), ncol(Y)),
    dimnames = list(colnames(X), colnames(X), colnames(Y))
  )

  out <- list(beta = pmax(beta, 0), sigmas = sigmas)
  return(out)
}





#' Derive background at the scale of the normalized data for GeoMx data
#'
#' Estimates per-datapoint background levels from a GeoMx experiment.
#' In studies with two or more probe pools, different probes will have different
#' background levels. This function provides a convenient way to account for this phenomenon.
#'
#' @param norm Matrix of normalized data, genes in rows and segments in columns.
#'  Must include negprobes, and must have rownames.
#' @param probepool Vector of probe pool names for each gene, aligned to the rows of "norm".
#' @param negnames Names of all negProbes in the dataset. Must be at least one neg.name within each probe pool.
#' @return A matrix of expected background values, in the same scale and dimensions as the "norm" argument.
#' @examples
#' data(mini_geomx_dataset)
#' # estimate background:
#' mini_geomx_dataset$bg <- derive_GeoMx_background(
#'   norm = mini_geomx_dataset$normalized,
#'   probepool = rep(1, nrow(mini_geomx_dataset$normalized)),
#'   negnames = "NegProbe"
#' )
#' @export
derive_GeoMx_background <- function(norm, probepool, negnames) {

  # check data input:
  if (nrow(norm) != length(probepool)) {
    stop("nrow(norm) != length(probepool)")
  }

  # initialize:
  bg <- norm * 0


  # fill in expected background at scale of normalized data:
  for (pool in unique(probepool)) {

    # get the pool's negProbes:
    tempnegs <- intersect(negnames, rownames(norm)[probepool == pool])
    if (length(tempnegs) == 0) {
      stop(paste0(pool, " probe pool didn't have any negprobes specified"))
    }
    tempnegfactor <- colMeans(norm[tempnegs, , drop = FALSE])

    # fill in the corresponding elements of bg:
    bg[probepool == pool, ] <- sweep(bg[probepool == pool, ], 2, tempnegfactor, "+")
  }
  return(bg)
}




#' Compute gene weights
#'
#' Compute gene weights from pre-defined biological noise estimates and from
#'  raw count/ error-model-defined technical noise estimates
#' @param norm Matrix of data used in decon. Used to define the gene list and the
#' shape of the output "wts" matrix.
#' @param raw Matrix of raw data. If provided, used to define technical noise
#' @param error.model Which error model to use. Defaults to "dsp"
#' @param weight.by.TIL.resid.sd If TRUE, then genes are weighted in part based on their
#'  biological variability as estimated by their residual SD from decon performed on TCGA.
#' @return A matrix of weights, in the same dimension as norm  
deriveWeights <- function(norm, raw = NULL, error.model = "dsp", weight.by.TIL.resid.sd = FALSE) {

  # get tech SDs if raw data provided:
  if (length(raw) == 0) {
    sds.tech <- matrix(0.1, nrow(raw), ncol(raw), dimnames = dimnames(raw))
  }
  if (length(raw) > 0) {
    sds.tech <- runErrorModel(
      counts = raw,
      platform = "dsp"
    )
  }

  # if the mean.resid.sd vector (which defines genes' biological SD) is in the environment,
  # get biological noise:
  if (!weight.by.TIL.resid.sd) {
    sds.bio <- matrix(0.1, nrow(raw), ncol(raw), dimnames = dimnames(raw))
  }
  if (weight.by.TIL.resid.sd) {
    sds.bio <- matrix(NA, nrow(raw), ncol(raw), dimnames = dimnames(raw))
    for (gene in intersect(names(SpatialDecon::mean.resid.sd), rownames(sds.bio))) {
      sds.bio[gene, ] <- SpatialDecon::mean.resid.sd[gene]
    }
    sds.bio <- replace(sds.bio, is.na(sds.bio), mean(sds.bio, na.rm = TRUE))
  }

  # define total SD, and invert to get weights
  sds.tot <- sqrt(sds.tech^2 + sds.bio^2)
  wts <- 1 / sds.tech
  return(wts)
}





#' Download a cell profile matrix
#'
#' Download a cell profile matrix from the online library
#'
#' @param matrixname A name
#' @return A cell profile matrix
#' @details Valid values for the matrixname argument include:
#' \itemize{
#' \item Airway_Epithelium
#' \item Atlas_Adult_Retina_10x
#' \item Census_Adult_Immune_10x
#' \item Census_Newborn_Blood_10x
#' \item Diff_Fetal_Neuron_SS2
#' \item FetalMaternal_Adult_Blood_10x
#' \item FetalMaternal_Adult_Blood_SS2
#' \item FetalMaternal_Adult_Decidua_10x
#' \item FetalMaternal_Adult_Decidua_SS2
#' \item FetalMaternal_Fetal_Placenta_10x
#' \item Human_brain
#' \item Human_Cell_Landscape
#' \item IBD_Adult_Colon_10x
#' \item Landscape_Adult_Liver_10x
#' \item Lung_plus_neutrophils
#' \item Mouse_Brain
#' \item Profiling_Adult_BoneMarrow_10x
#' \item Reprogram_Embryo_Dendritic_10x
#' \item Sensitivity_Adult_Esophagus_10x
#' \item Sensitivity_Adult_Lung_10x
#' \item Sensitivity_Adult_Spleen_10x
#' \item Somatic_Adult_Pancreas_SS2
#' \item SpatioTemporal_Adult_Kidney_10x
#' \item SpatioTemporal_Fetal_Kidney_10x
#' \item Tcell_Adult_Blood_10x
#' \item Tcell_Adult_BoneMarrow_10x
#' \item Tcell_Adult_Lung_10x
#' \item Tcell_Adult_LymphNode_10x
#' }
#' @examples
#' X <- download_profile_matrix(matrixname = "Human_brain")
#' head(X)
#' @export
download_profile_matrix <- function(matrixname) {

  # check formatting:

  if (length(matrixname) > 1) {
    stop("specify just one matrixname")
  }

  librarynames <- c(
    "Airway_Epithelium", "Atlas_Adult_Retina_10x", "Census_Adult_Immune_10x",
    "Census_Newborn_Blood_10x", "Diff_Fetal_Neuron_SS2", "FetalMaternal_Adult_Blood_10x",
    "FetalMaternal_Adult_Blood_SS2", "FetalMaternal_Adult_Decidua_10x",
    "FetalMaternal_Adult_Decidua_SS2", "FetalMaternal_Fetal_Placenta_10x", "Human_brain",
    "Human_Cell_Landscape", "IBD_Adult_Colon_10x", "Landscape_Adult_Liver_10x",
    "Lung_plus_neutrophils", "Mouse_Brain", "Profiling_Adult_BoneMarrow_10x",
    "Reprogram_Embryo_Dendritic_10x", "Sensitivity_Adult_Esophagus_10x",
    "Sensitivity_Adult_Lung_10x", "Sensitivity_Adult_Spleen_10x", "Somatic_Adult_Pancreas_SS2",
    "SpatioTemporal_Adult_Kidney_10x", "SpatioTemporal_Fetal_Kidney_10x", "Tcell_Adult_Blood_10x",
    "Tcell_Adult_BoneMarrow_10x", "Tcell_Adult_Lung_10x", "Tcell_Adult_LymphNode_10x"
  )
  if (!is.element(matrixname, librarynames)) {
    warning(paste0(matrixname, " is not an expected cell profile matrix name."))
  }

  # X = as.matrix(utils::read.csv(paste0("https://github.com/Nanostring-Biostats/Extensions/blob/refactor/cell-profile-library/",
  X <- as.matrix(utils::read.csv(paste0(
    "https://raw.githubusercontent.com/patrickjdanaher/cell-profile-library/master/profile_matrices/",
    matrixname, ".csv"
  ), row.names = 1))

  X <- X[rowSums(X) > 0, ]
  return(X)
}




#' Identify outlier genes in a decon result
#'
#' Analyses a decon result's residuals to identify poorly-fit genes and flag them for removal.
#'  Rule: flag anything with
#'
#' @param Y p-length expression vector or p * N expression matrix - the actual (linear-scale) data
#' @param yhat Expectation of Y given the decon fit
#' @param resids Log2-scale residuals of Y vs. yhat (log2(pmax(Y, 0.5)) - log2(yhat))
#' @param wts Matrix of data point weights, aligned to dimensions of resids
#' @param resid_thresh A scalar, sets a threshold on how extreme individual data points' values
#'  can be (in log2 units) before getting flagged as outliers and set to NA.
#' @return a vector of names of poorly-fit genes
#' @export
flagOutliers <- function(Y, yhat, resids, wts, resid_thresh = 3) {

  # get weighted resids:
  if (length(wts) == 0) {
    wres <- resids
  }
  if (length(wts) > 0) {
    wres <- resids * wts
  }

  # flag bad genes:
  outlier_genes <- c() # <------------------- this line makes it so no outlier genes are filtered
  # flag bad data points: (not doing anything for now)
  outlier_data_points <- abs(resids) > resid_thresh
  return(outlier_data_points)
}




#' Draw coxcomb plots as points in a graphics window
#'
#' Draws a scatterplot where each point is a circular barplot, intended to show decon results
#'
#' @param x Vector of x coordinates
#' @param y Vector of y coordinates
#' @param b matrix or cell abundances, with columns aligned with the elements of x and y
#' @param col vector of colors, aligned to the rows of b.
#' @param legendwindow Logical. If TRUE, the function draws a color legend in a new window
#' @param rescale.by.sqrt Logical, for whether to rescale b by its square root to make value proportional to
#'  shape area, not shape length.
#' @param border Color of pie segment border, defauls to NA/none
#' @param add Logical. If TRUE, the function draws florets atop an existing graphics device (TRUE) or call a new device (FALSE).
#' @param cex Floret size. Florets are scaled relative to the range of x and y; this further scales up or down.
#' @param bty bty argument passed to plot()
#' @param xaxt xaxt argument passed to plot()
#' @param yaxt yaxt argument passed to plot()
#' @param xlab xlab, defaults to ""
#' @param ylab ylab, defaults to ""
#' @param ... additional arguments passed to plot()
#' @return Draws a coxcomb plot, returns no data. 
#' @examples
#' data(mini_geomx_dataset)
#' # estimate background:
#' mini_geomx_dataset$bg <- derive_GeoMx_background(
#'   norm = mini_geomx_dataset$normalized,
#'   probepool = rep(1, nrow(mini_geomx_dataset$normalized)),
#'   negnames = "NegProbe"
#' )
#' # run basic decon:
#' res0 <- spatialdecon(
#'   norm = mini_geomx_dataset$normalized,
#'   bg = mini_geomx_dataset$bg,
#'   X = safeTME
#' )
#' # draw florets:
#' florets(
#'   x = mini_geomx_dataset$annot$x,
#'   y = mini_geomx_dataset$annot$y,
#'   b = res0$beta, cex = 2
#' )
#' @export
florets <- function(x, y, b, col = NULL, legendwindow = FALSE, rescale.by.sqrt = TRUE,
                    border = NA, add = FALSE, cex = 1,
                    bty = "n", xaxt = "n", yaxt = "n", xlab = "", ylab = "", ...) {
  # rescale b by sqrt so magnitude is proportional to coxcomb area, not length
  if (rescale.by.sqrt) {
    b <- sqrt(b)
  }
  # make b a matrix:
  if (is.vector(b)) {
    b2 <- matrix(b, nrow = length(b))
    rownames(b2) <- names(b)
    b <- b2
    rm(b2)
  }
  # choose colors if not given:
  if ((length(col) == 0) & all(is.element(rownames(b), names(SpatialDecon::cellcols)))) {
    col <- SpatialDecon::cellcols[rownames(b)]
  }
  if ((length(col) == 0) & !all(is.element(rownames(b), names(SpatialDecon::cellcols)))) {
    manycols <- c(
      "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69",
      "#FCCDE5", "#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FB9A99", "#E31A1C",
      "#FDBF6F", "#FF7F00", "#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E",
      "#E6AB02", "#A6761D", "#666666", sample(grDevices::colors(), 99)
    )
    col <- manycols[seq_len(nrow(b))]
    names(col) <- rownames(b)
  }
  # convert colors to matrix of the same dimension as b:
  if (length(col) == 1) {
    col <- matrix(col, nrow = nrow(b), ncol = ncol(b))
  }
  if (is.vector(col)) {
    col <- matrix(col, nrow = nrow(b), ncol = ncol(b))
  }

  # get radians:
  # angles = seq(0, 2 * pi, length.out = nrow(b) + 1)[-1]
  angles <- seq(0, 2 * pi, length.out = nrow(b) + 1)

  # scale b based on the range of x and y:
  maxrange <- max(diff(range(x, na.rm = TRUE)), diff(range(y, na.rm = TRUE)))
  b <- b * maxrange / mean(b, na.rm = TRUE) * 0.007 * cex


  # draw plot:
  if (!add) {
    graphics::plot(x, y, col = 0, bty = bty, xaxt = xaxt, yaxt = yaxt, xlab = xlab, ylab = ylab, ...)
  }

  # draw florets:
  if (nrow(b) > 1) {
    for (i in seq_len(length(x))) {
      for (j in seq_len(nrow(b))) {
        tempangles <- seq(angles[j], angles[j + 1], length.out = 20)
        xt <- b[j, i] * cos(tempangles)
        yt <- b[j, i] * sin(tempangles)
        graphics::polygon(x[i] + c(0, xt), y[i] + c(0, yt), col = col[j, i], border = border, lwd = 0.5)
      }
    }
  }

  # if just one point, draw a full circle:
  if (nrow(b) == 1) {
    for (i in seq_len(length(x))) {
      for (j in seq_len(nrow(b))) {
        tempangles <- seq(angles[j], angles[j + 1], length.out = 20)
        xt <- b[j, i] * cos(tempangles)
        yt <- b[j, i] * sin(tempangles)
        graphics::polygon(x[i] + xt, y[i] + yt, col = col[j], border = border, lwd = 0.5)
      }
    }
  }

  # draw a legend:
  if (legendwindow) {
    graphics::plot(0, 0, col = 0, xlim = c(-1, 1), ylim = c(-1, 1), xaxt = "n", yaxt = "n", xlab = "", ylab = "", ...)
    for (j in seq_len(length(angles))) {
      graphics::lines(c(0, 0.75 * cos(angles[j])), c(0, 0.75 * sin(angles[j])), col = col[j], lwd = 2)
      graphics::text(0.85 * cos(angles[j]), 0.85 * sin(angles[j]), rownames(b)[j], cex = 1.4)
    }
  }
}





#' Estimate a tumor-specific profile and merge it with the pre-specified cell profile matrix (X)
#'
#' Given the input of "tumor-only" AOI's, estimates an collection of tumor-specific
#' expression profiles and merges them with the immune cell expression training matrix.
#' The process:
#' \enumerate{
#' \item log2/normalized data from tumor-only AOIs is clustered with hclust,
#' and cutree() is used to define clusters.
#' \item 2. Each cluster's geomean profile is merged into the immune cell profile matrix.
#' }
#'
#' @param norm matrix of normalized data
#' @param bg matrix of expected background, on the scale of norm.
#' @param pure_tumor_ids Vector identifying columns of norm that are pure tumor.
#'  Can be indices, logicals or column names.
#' @param X The training matrix
#' @param K the number of clusters to fit
#' @return an updated X matrix with new columns, "tumor.1", "tumor.2", ...
#' @examples
#' data(mini_geomx_dataset)
#' mini_geomx_dataset$bg <- derive_GeoMx_background(
#'   norm = mini_geomx_dataset$normalized,
#'   probepool = rep(1, nrow(mini_geomx_dataset$normalized)),
#'   negnames = "NegProbe"
#' )
#' safeTME.with.tumor <- mergeTumorIntoX(
#'   norm = mini_geomx_dataset$norm,
#'   bg = mini_geomx_dataset$bg,
#'   pure_tumor_ids = mini_geomx_dataset$annot$AOI.name == "Tumor",
#'   X = safeTME,
#'   K = 3
#' )
#' @export
mergeTumorIntoX <- function(norm, bg, pure_tumor_ids, X, K = 10) {

  # round up 0 values in norm:
  min.nonzero <- min(norm[norm > 0], na.rm = TRUE)
  norm <- pmax(norm, min.nonzero)

  # subset data to only the pure tumor IDs:
  norm <- norm[, pure_tumor_ids, drop = FALSE]
  bg <- bg[, pure_tumor_ids, drop = FALSE]

  # bg-subtract:
  norm <- pmax(norm - bg, min(norm) / 20)

  # fix K if too big:
  if (ncol(norm) < K) {
    K <- ncol(norm)
  }

  # case 1: want to use every column in norm as a separate profile:
  #  (includes case of just one column in norm)
  if (K == ncol(norm)) {
    tumorX <- norm
  }

  # case 2: if many tumor AOIs, get profiles for K clusters of data:
  if (K < ncol(norm)) {
    # cluster and cut:
    h <- stats::hclust(stats::dist(t(log2(norm))))
    cut <- stats::cutree(h, k = K)
    # get clusters' geomean profiles:
    tumorX <- c()
    for (cid in unique(cut)) {
      tumorX <- cbind(tumorX, exp(rowMeans(log(norm[, cut == cid, drop = FALSE]))))
    }
    colnames(tumorX) <- paste0("tumor.", seq_len(ncol(tumorX)))
  }

  # align tumorX with X:
  sharedgenes <- intersect(rownames(tumorX), rownames(X))
  tumorX <- tumorX[sharedgenes, ]
  X <- X[sharedgenes, ]

  # rescale tumor X:
  meanq90 <- max(mean(apply(X, 2, stats::quantile, 0.9)), 1e-3)
  tumorq90s <- apply(tumorX, 2, stats::quantile, 0.9)
  tumorX <- sweep(tumorX, 2, tumorq90s, "/") * meanq90

  # merge:
  out <- cbind(X, tumorX)
  return(out)
}





#' SpatialDecon: A package for computating the notorious bar statistic.
#'
#' The SpatialDecon package estimates mixed cell type abundance in the regions of spatially-resolved gene
#' expression studies, using the method of Danaher & Kim (2020), "Advances in mixed cell deconvolution enable
#' quantification of cell types in spatially-resolved gene expression data." 
#' It is also appropriate to apply to bulk gene expression data.
#' 
#' @section functions:
#' Functions to help set up deconvolution:
#' \itemize{
#'  \item derive_GeoMx_background Estimates the background levels from GeoMx experiments
#'  \item collapseCellTypes reformats deconvolution results to merge closely-related cell types
#'  \item download_profile_matrix Downloads a cell profile matrix. 
#'  \item safeTME: a data object, a matrix of immune cell profiles for use in tumor-immune deconvolution. 
#' }
#' Deconvolution functions:
#' \itemize{
#'  \item spatialdecon runs the core deconvolution function
#'  \item reverseDecon runs a transposed/reverse deconvolution problem, fitting the data as a function of cell abundance estimates. 
#'   Used to measure genes' dependency on cell mixing and to calculate gene residuals from cell mixing. 
#' }
#' Plotting functions:
#' \itemize{
#'  \item florets Plot cell abundance on a specified x-y space, with each point a cockscomb plot showing the cell abundances of that region/sample. 
#'  \item TIL_barplot Plot abundances of tumor infiltrating lymphocytes (TILs) estimated from the safeTME cell profile matrix
#' }
#' @examples
#' data(mini_geomx_dataset)
#' # estimate background:
#' mini_geomx_dataset$bg <- derive_GeoMx_background(
#'   norm = mini_geomx_dataset$normalized,
#'   probepool = rep(1, nrow(mini_geomx_dataset$normalized)),
#'   negnames = "NegProbe"
#' )
#' # run basic decon:
#' res0 <- spatialdecon(
#'   norm = mini_geomx_dataset$normalized,
#'   bg = mini_geomx_dataset$bg,
#'   X = safeTME
#' )
#' # run decon with bells and whistles:
#' res <- spatialdecon(
#'   norm = mini_geomx_dataset$normalized,
#'   bg = mini_geomx_dataset$bg,
#'   X = safeTME,
#'   cellmerges = safeTME.matches,
#'   cell_counts = mini_geomx_dataset$annot$nuclei,
#'   is_pure_tumor = mini_geomx_dataset$annot$AOI.name == "Tumor"
#' )
#' @docType package
#' @name SpatialDecon-package
NULL



#' Reverse deconvolution
#'
#' Performs "reverse deconvolution", modelling each gene expression's ~ cell scores.
#' Returns a matrix of "fitted" expression values, a matrix of residuals, a matrix of
#' reverse decon coefficients for genes * cells.
#'
#' @param norm Matrix of normalized data, with genes in rows and observations in columns
#' @param beta Matrix of cell abundance estimates, with cells in rows and observations in columns.
#'  Columns are aligned to "norm".
#' @param epsilon All y and yhat values are thresholded up to this point when performing decon.
#'  Essentially says, "ignore variability in counts below this threshold."
#' @return A list:
#' \itemize{
#' \item coefs, a matrix of coefficients for genes * cells, where element i,j is interpreted as
#' "every unit increase in cell score j is expected to increase expression of gene i by _".
#' \item yhat, a matrix of fitted values, in the same dimension as norm
#' \item resids, a matrix of log2-scale residuals from the reverse decon fit, in the same
#'  dimension as norm
#' \item cors, a vector giving each gene's correlation between fitted and observed expression
#' \item resid.sd, a vector of each gene's residual SD, a metric of how much variability genes
#'  have independend of cell mixing.
#' }
#' @import logNormReg
#' @examples
#' data(mini_geomx_dataset)
#' # estimate background:
#' mini_geomx_dataset$bg <- derive_GeoMx_background(
#'   norm = mini_geomx_dataset$normalized,
#'   probepool = rep(1, nrow(mini_geomx_dataset$normalized)),
#'   negnames = "NegProbe"
#' )
#' # run basic decon:
#' res0 <- spatialdecon(
#'   norm = mini_geomx_dataset$normalized,
#'   bg = mini_geomx_dataset$bg,
#'   X = safeTME
#' )
#' # run reverse decon:
#' rdecon <- reverseDecon(
#'   norm = mini_geomx_dataset$norm,
#'   beta = res0$beta
#' )
#' @export
reverseDecon <- function(norm, beta, epsilon = NULL) {

  # remove cell types with no SD:
  beta = beta[apply(beta, 1, stats::sd) > 0, ]
  
  # run reverse decon for all genes:
  rd <- function(y) {
    fit <- logNormReg::lognlm(y ~ t(beta),
      lik = FALSE,
      method = "L-BFGS-B",
      lower = rep(0, ncol(beta) + 1),
      upper = rep(Inf, ncol(beta) + 1),
      opt = "optim",
      control = list(maxit = 1000)
    )
    return(fit$coefficients)
  }
  coefs <- t(apply(norm, 1, rd))
  colnames(coefs)[-1] <- rownames(beta)

  # get yhat
  yhat <- norm * NA
  for (ind in seq_len(ncol(yhat))) {
    yhat[, ind] <- coefs %*% c(1, beta[, ind])
  }

  # auto-select a reasonable epsilon if not provided
  if (length(epsilon) == 0) {
    epsilon <- stats::quantile(norm[norm > 0], 0.01)
  }

  # get resids:
  resids <- log2(pmax(norm, epsilon)) - log2(pmax(yhat, epsilon))

  # get summary stats:
  cors <- suppressWarnings(diag(stats::cor(t(norm), t(yhat))))
  resid.sd <- apply(resids, 1, stats::sd)

  out <- list(coefs = coefs, yhat = yhat, resids = resids, cors = cors, resid.sd = resid.sd)
  return(out)
}





#' Apply error model to estimate technical SD from raw counts
#'
#' Based on raw counts, uses past data to estimate each raw count's log-scale SD from technical noise.
#' Sppecifies different error models for different platforms.
#'
#' @param counts vector or matrix of raw counts
#' @param platform String specifying which platform was used to create "rawCounts". Default to "dsp".
#'  Other options include "ncounter", "rsem" and "quantile".
#' @return a matrix of log2-scale SDs
runErrorModel <- function(counts, platform = "general") {
  if (platform == "ncounter") {
    sds <- counts * 0 + 0.1
    sds <- replace(sds, counts < 200, 0.2)
    sds <- replace(sds, counts < 100, 0.3)
    sds <- replace(sds, counts < 75, 0.4)
    sds <- replace(sds, counts < 50, 0.5)
    sds <- replace(sds, counts < 40, 0.7)
    sds <- replace(sds, counts < 30, 1)
    sds <- replace(sds, counts < 20, 3)
  }


  if (platform == "rsem") {
    sds <- counts * 0 + 0.5930982
    sds <- replace(sds, log2(counts) < 9.5, 0.6458475)
    sds <- replace(sds, log2(counts) < 8.5, 0.7847597)
    sds <- replace(sds, log2(counts) < 7.5, 1.0576471)
    sds <- replace(sds, log2(counts) < 6.5, 1.2990917)
    sds <- replace(sds, log2(counts) < 5.5, 1.5061735)
    sds <- replace(sds, log2(counts) < 4.5, 1.6930872)
    sds <- replace(sds, log2(counts) < 3.5, 1.7894239)
  }

  if (platform == "dsp") {
    predictsd.dsp <- function(rawcounts) {
      m <- log2(pmax(rawcounts, 1e-3))
      meanvec <- c(-1e-6, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6, Inf)
      sdvec <- c(1.5, 1.383, 1.191, 0.800, 0.48, 0.301, 0.301, 0.301, 0.263, 0.235, 0.235)

      s <- replace(m, TRUE, sdvec[1])
      for (i in seq_len(length(meanvec) - 1)) {
        s <- replace(s, m >= meanvec[i], sdvec[i + 1])
      }
      return(s)
    }

    if (is.vector(counts)) {
      sds <- sapply(counts, predictsd.dsp)
    }
    if (is.matrix(counts)) {
      sds <- predictsd.dsp(counts)
    }
  }


  if (platform == "quantile") {
    if (is.vector(counts)) {
      quantile <- rank(counts) / length(counts)
    }
    if (is.matrix(counts)) {
      quantile <- matrix(rank(counts), nrow(counts)) / length(counts)
    }

    sds <- quantile * 0 + 0.1
    sds <- replace(sds, quantile < 0.2, 0.2)
    sds <- replace(sds, quantile < 0.15, 0.3)
    sds <- replace(sds, quantile < 0.1, 0.4)
    sds <- replace(sds, quantile < 0.05, 0.5)
    sds <- replace(sds, quantile < 0.01, 1)
  }
  return(sds)
}




#' Mixed cell deconvolution of spatiall-resolved gene expression data
#'
#' Runs the spatialdecon algorithm with added optional functionalities.
#' Workflow is:
#' \enumerate{
#' \item compute weights from raw data
#' \item Estimate a tumor profile and merge it into the cell profiles matrix
#' \item run deconvolution once
#' \item remove poorly-fit genes from first round of decon
#' \item re-run decon with cleaned-up gene set
#' \item combine closely-related cell types
#' \item compute p-values
#' \item rescale abundance estimates, to proportions of total, proportions of immune, cell counts
#' }
#'
#' @param norm p-length expression vector or p * N expression matrix - the actual (linear-scale) data
#' @param bg Same dimension as norm: the background expected at each data point.
#' @param X Cell profile matrix. If NULL, the safeTME matrix is used.
#' @param raw Optional for using an error model to weight the data points.
#'  p-length expression vector or p * N expression matrix - the raw (linear-scale) data
#' @param wts Optional, a matrix of weights.
#' @param resid_thresh A scalar, sets a threshold on how extreme individual data points' values
#'  can be (in log2 units) before getting flagged as outliers and set to NA.
#' @param lower_thresh A scalar. Before log2-scale residuals are calculated, both observed and fitted
#'  values get thresholded up to this value. Prevents log2-scale residuals from becoming extreme in
#'  points near zero.
#' @param align_genes Logical. If TRUE, then Y, X, bg, and wts are row-aligned by shared genes.
#' @param is_pure_tumor A logical vector denoting whether each AOI consists of pure tumor. If specified,
#'  then the algorithm will derive a tumor expression profile and merge it with the immune profiles matrix.
#' @param cell_counts Number of cells estimated to be within each sample. If provided alongside norm_factors,
#'  then the algorithm will additionally output cell abundance esimtates on the scale of cell counts.
#' @param cellmerges A list object holding the mapping from beta's cell names to combined cell names. If left
#'  NULL, then defaults to a mapping of granular immune cell definitions to broader categories.
#' @param n_tumor_clusters Number of tumor-specific columns to merge into the cell profile matrix.
#'  Has an impact only when is_pure_tumor argument is used to indicate pure tumor AOIs.
#'  Takes this many clusters from the pure-tumor AOI data and gets the average expression profile in each cluster.  Default 10.
#' @param maxit Maximum number of iterations. Default 1000.
#' @return a list:
#' \itemize{
#' \item beta: matrix of cell abundance estimates, cells in rows and observations in columns
#' \item sigmas: covariance matrices of each observation's beta estimates
#' \item p: matrix of p-values for H0: beta == 0
#' \item t: matrix of t-statistics for H0: beta == 0
#' \item se: matrix of standard errors of beta values
#' \item prop_of_all: rescaling of beta to sum to 1 in each observation
#' \item prop_of_nontumor: rescaling of beta to sum to 1 in each observation, excluding tumor abundance estimates
#' \item cell.counts: beta rescaled to estimate cell numbers, based on prop_of_all and nuclei count
#' \item beta.granular: cell abundances prior to combining closely-related cell types
#' \item sigma.granular: sigmas prior to combining closely-related cell types
#' \item cell.counts.granular: cell.counts prior to combining closely-related cell types
#' \item resids: a matrix of residuals from the model fit. (log2(pmax(y, lower_thresh)) - log2(pmax(xb, lower_thresh))).
#' \item X: the cell profile matrix used in the decon fit.
#' }
#' @examples
#' data(mini_geomx_dataset)
#' # estimate background:
#' mini_geomx_dataset$bg <- derive_GeoMx_background(
#'   norm = mini_geomx_dataset$normalized,
#'   probepool = rep(1, nrow(mini_geomx_dataset$normalized)),
#'   negnames = "NegProbe"
#' )
#' # run basic decon:
#' res0 <- spatialdecon(
#'   norm = mini_geomx_dataset$normalized,
#'   bg = mini_geomx_dataset$bg,
#'   X = safeTME
#' )
#' # run decon with bells and whistles:
#' res <- spatialdecon(
#'   norm = mini_geomx_dataset$normalized,
#'   bg = mini_geomx_dataset$bg,
#'   X = safeTME,
#'   cellmerges = safeTME.matches,
#'   cell_counts = mini_geomx_dataset$annot$nuclei,
#'   is_pure_tumor = mini_geomx_dataset$annot$AOI.name == "Tumor"
#' )
#' @export
spatialdecon <- function(norm, bg, X = NULL,
                         raw = NULL, wts = NULL,
                         resid_thresh = 3, lower_thresh = 0.5,
                         align_genes = TRUE,
                         is_pure_tumor = NULL, n_tumor_clusters = 10,
                         cell_counts = NULL,
                         cellmerges = NULL,
                         maxit = 1000) {

  #### preliminaries ---------------------------------

  # check formatting:
  if (!is.matrix(norm)) {
    stop("norm should be a matrix")
  }
  if ((length(X) > 0) & (!is.matrix(X))) {
    stop("X should be a matrix")
  }
  if ((length(raw) > 0) & (!is.matrix(raw))) {
    stop("raw must be numeric")
  }
  if ((length(wts) > 0) & (!is.matrix(wts))) {
    stop("wts must be numeric")
  }
  if ((length(cell_counts) > 0) & (!is.numeric(cell_counts))) {
    stop("cell_counts must be numeric")
  }


  if (length(bg) == 1) {
    bg <- matrix(bg, nrow(norm), ncol(norm), dimnames = list(rownames(norm), colnames(norm)))
  }

  # calculate weights based on expected SD of counts
  # wts = replace(norm, TRUE, 1)
  if (length(raw) > 0) {
    wts <- deriveWeights(norm,
      raw = raw, error.model = "dsp",
      weight.by.TIL.resid.sd = TRUE
    )
  }

  # prep training matrix:
  if (length(X) == 0) {
    X <- SpatialDecon::safeTME
  }
  sharedgenes <- intersect(rownames(norm), rownames(X))
  if (length(sharedgenes) == 0) {
    stop("no shared gene names between norm and X")
  }
  if (length(sharedgenes) < 100) {
    stop(paste0("Only ", length(sharedgenes), " genes are shared between norm and X - this may not be enough to support accurate deconvolution."))
  }

  #### if pure tumor AOIs are specificed, get tumor expression profile -------------------------------------
  if (sum(is_pure_tumor) > 0) {

    # derive tumor profiles and merge into X: (derive a separate profile for each tissue)
    X <- mergeTumorIntoX(
      norm = norm,
      bg = bg,
      pure_tumor_ids = is_pure_tumor,
      X = X[sharedgenes, ],
      K = n_tumor_clusters
    )

    sharedgenes <- intersect(rownames(norm), rownames(X))
  }


  #### Run decon  -----------------------------------
  res <- algorithm2(
    Y = norm[sharedgenes, ],
    bg = bg[sharedgenes, ],
    X = X[sharedgenes, ],
    weights = wts[sharedgenes, ],
    maxit = maxit
  )


  #### combine closely-related cell types ------------------------------------

  if (length(cellmerges) > 0) {

    # if (is.element("tumor", rownames(res$beta))) {
    #  cellmerges$tumor = rownames(res$beta)[grepl("tumor", rownames(res$beta))]
    # }
    tempconv <- convertCellTypes(
      beta = res$beta,
      matching = cellmerges,
      stat = sum,
      na.rm = FALSE,
      sigma = res$sigmas
    )
    # overwrite original beta with merged beta:
    res$beta.granular <- res$beta
    res$sigma.granular <- res$sigmas
    res$sigmas <- NULL
    res$beta <- tempconv$beta
    res$sigma <- tempconv$sigma
  }


  #### compute p-values -------------------------------------------
  tempbeta <- res$beta
  tempse <- tempp <- tempt <- tempbeta * NA
  for (i in seq_len(ncol(tempse))) {
    tempse[, i] <- suppressWarnings(sqrt(diag(res$sigma[, , i])))
  }
  tempt <- (tempbeta / tempse)
  tempp <- 2 * (1 - stats::pt(tempt, df = length(sharedgenes) - ncol(X) - 1))
  res$p <- tempp
  res$t <- tempt
  res$se <- tempse


  #### rescale abundance estimates --------------------------------
  # (to proportions of total, proportions of immune, cell counts)

  # proportions:
  res$prop_of_all <- sweep(res$beta, 2, colSums(res$beta), "/")
  nontumorcellnames <- rownames(res$beta)[!grepl("tumor", rownames(res$beta))]
  res$prop_of_nontumor <- sweep(res$beta[nontumorcellnames, ], 2, colSums(res$beta[nontumorcellnames, ]), "/")

  # on scale of cell counts:
  if (length(cell_counts) > 0) {
    res$cell.counts <- convertCellScoresToCounts(
      beta = res$beta,
      nuclei.counts = cell_counts,
      omit.tumor = TRUE
    )
    if (exists("res$beta.granular") > 0) {
      res$cell.counts.granular <- convertCellScoresToCounts(
        beta = res$beta.granular,
        nuclei.counts = cell_counts,
        omit.tumor = TRUE
      )
    }
  }

  # add other pertinent info to res:
  res$X <- X[rownames(res$resids), ]
  return(res)
}





#' Barplot of abundance estimates
#'
#' Draw barplot of the "betas" from a decon fit
#'
#' @param mat Matrix of cell proportions or abundances, in the same dimensions output by spatialdecon
#'  (cells in rows, observations in columns). User is free to re-order columns/observations in
#'  whatever order is best for display.
#' @param draw_legend Logical. If TRUE, the function draws a legend in a new plot frame.
#' @param main Title for barplot
#' @param col Vector of colors for cell types. Defaults to pre-set colors for the safeTME cell types. 
#' @param ... Arguments passed to barplot()
#' @examples
#' data(mini_geomx_dataset)
#' # estimate background:
#' mini_geomx_dataset$bg <- derive_GeoMx_background(
#'   norm = mini_geomx_dataset$normalized,
#'   probepool = rep(1, nrow(mini_geomx_dataset$normalized)),
#'   negnames = "NegProbe"
#' )
#' # run basic decon:
#' res0 <- spatialdecon(
#'   norm = mini_geomx_dataset$normalized,
#'   bg = mini_geomx_dataset$bg,
#'   X = safeTME
#' )
#' # run barplot:
#' TIL_barplot(mat = res0$beta)
#' # run barplot and draw a color legend
#' TIL_barplot(mat = res0$beta, draw_legend = TRUE)
#' @export
TIL_barplot <- function(mat, draw_legend = FALSE, main = "", col = NULL, ...) {

  
  # infer colors:
  if (length(col) == 0) {
    # use safeTME colors if the right cells are present:
    if (all(is.element(rownames(mat), names(SpatialDecon::cellcols)))) {
      col <- SpatialDecon::cellcols[rownames(mat)]
    }
    else {
      manycols <- c(
        "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69",
        "#FCCDE5", "#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FB9A99", "#E31A1C",
        "#FDBF6F", "#FF7F00", "#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E",
        "#E6AB02", "#A6761D", "#666666", sample(grDevices::colors(), 99)
      )
      col <- manycols[seq_len(nrow(mat))]
      names(col) <- rownames(mat)
    }
  }
  
  
  #  usecells <- intersect(rownames(mat), names(SpatialDecon::cellcols))
  usecells <- rownames(mat)
  
  # draw barplot:
  graphics::barplot(mat[usecells, ],
    cex.lab = 1.5,
    col = col, border = NA,
    las = 2, main = main, ...
  )

  # draw a legend:
  if (draw_legend) {
    graphics::frame()
    graphics::legend("center",
      fill = rev(col),
      legend = rev(names(col))
    )
  }
}

